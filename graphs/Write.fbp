EXPORT=URL.IN:SERVER
EXPORT=ERROR.OUT:ERROR
EXPORT=FILTERTOKEN.IN:IN
EXPORT=CONSTRUCT.PKEY:PKEY
EXPORT=READY.OUT:READY
EXPORT=PACKETIZE.OUT:OUT
EXPORT=WRITESERVER.QUIT:QUIT
EXPORT=SENDFILTER.IN:FILTER

'.+' -> REGEXP FilterToken(groups/FilterByGroup)
'true' -> RECURSE FilterAttributes(objects/FilterProperty)
'^_.+' -> WITH SendFilter(packets/SendWith) OUT -> KEY FilterAttributes()
FilterToken() OUT -> IN Sanitize(pgorm/SanitizeObjects) OUT -> IN Construct(pgorm/ConstructWrite)
Url(Split) OUT -> SERVER WriteServer(pg/Postgres) ERROR -> IN Error(Merge)

FilterToken() GROUP -> TOKEN WriteServer()
Construct() TEMPLATE -> TEMPLATE WriteServer()
Construct() OUT -> IN WriteServer()

# Convert to NoFlo packets

'out' -> KEY ExtractRow(objects/ExtractProperty)
'_type' -> PROPERTY GroupByType(underscore/GroupBy)
WriteServer() OUT -> IN ExtractRow() OUT -> IN ParseRows(strings/ParseJson) OUT -> IN GroupByType() OUT -> IN FilterAttributes() OUT -> IN Packetize(adapters/ObjectToPackets)

# Setup automatic filtering

Url() OUT -> SERVER ConfigServer(pg/Postgres) ERROR -> IN Error()

'columns' -> STRING ColumnsToken(SendString)
'SELECT information_schema.columns.table_name, information_schema.columns.column_name FROM information_schema.columns, information_schema.tables WHERE information_schema.tables.table_schema = 'public' AND information_schema.columns.table_name = information_schema.tables.table_name;' -> STRING ReadColumns(SendString)
' ' -> STRING ColumnsActivator(SendString)

Url() OUT -> IN ColumnsToken() OUT -> TOKEN ConfigServer()
Url() OUT -> IN ReadColumns() OUT -> TEMPLATE ConfigServer()
Url() OUT -> IN ColumnsActivator() OUT -> IN ConfigServer()

'columns' -> REGEXP FilterColumns(groups/FilterByGroup)
'table_name' -> GROUPING GroupColumnsByTable(objects/GroupValueByAnother)
'column_name' -> ENCLOSED GroupColumnsByTable()
ConfigServer() OUT -> IN FilterColumns() OUT -> IN GroupColumnsByTable() OUT -> IN Definitions(Split)

Definitions() OUT -> DEFINITION Sanitize()
Definitions() OUT -> IN Ready(Kick)
